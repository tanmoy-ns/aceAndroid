# -*- coding: utf-8 -*-
"""tugas ai

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1wSXN39H0GBHoxtTvpn0TDAEd2nlAW7Hr
"""

!pip install -q kaggle
!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle//
!ls ~/.kaggle
!chmod 600 /root/.kaggle/kaggle.json

!kaggle datasets download alviansyz/pisang

!ls

import pandas as pd
import zipfile
zip_ref = zipfile.ZipFile('pisang.zip', 'r')
zip_ref.extractall('data')
zip_ref.close()

pip install split-folders

import os
import splitfolders

base_dir = '/content/data/'
output_dir = '/content/model'
splitfolders.ratio(base_dir, output=output_dir, seed=1337, ratio=(.8, .2))
train_dir = os.path.join(output_dir, 'train')
validation_dir = os.path.join(output_dir, 'val')

import tensorflow as tf
from tensorflow.keras.optimizers import RMSprop
from tensorflow.keras.preprocessing.image import ImageDataGenerator

train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,
    horizontal_flip=True,
    shear_range=0.2,
    fill_mode= 'nearest'
)

test_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,
    horizontal_flip=True,
    shear_range=0.2,
    fill_mode= 'nearest'
)

train_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size = (150, 150),
    batch_size=32, 
    class_mode='categorical'
)

validation_generator = train_datagen.flow_from_directory(
    validation_dir, 
    target_size = (150, 150), 
    batch_size=32, 
    class_mode='categorical'
)

from tensorflow.keras.applications import ResNet152V2
from tensorflow.keras.layers import Input
from keras.applications import VGG16

model = tf.keras.models.Sequential([
                # VGG16(weights="imagenet", include_top=False, input_tensor=Input(shape=(150, 150, 3))),
                VGG16(include_top=False, input_tensor=Input(shape=(150, 150, 3)), pooling='avg'),
                # tf.keras.layers.Conv2D(32, (3,3), activation='relu',padding='same', input_shape=(150, 150, 3)),
                # tf.keras.layers.MaxPool2D(2, 2),
                # tf.keras.layers.Conv2D(64, (3,3), activation='relu',padding='same'),
                # tf.keras.layers.MaxPool2D(2,2),
                # tf.keras.layers.Conv2D(128, (3,3), activation='relu',padding='same'),
                # tf.keras.layers.MaxPool2D(2,2),
                # tf.keras.layers.Conv2D(128, (3,3), activation='relu',padding='same'),
                # tf.keras.layers.MaxPool2D(2,2),
                tf.keras.layers.Flatten(),
                # tf.keras.layers.Dropout(0.5),
                tf.keras.layers.Dense(512, activation='relu'),
                # tf.keras.layers.Dropout(0.25),
                tf.keras.layers.Dense(12, activation='softmax')                              
])

model.compile(loss='categorical_crossentropy',
              optimizer=tf.keras.optimizers.SGD(lr=1.0000e-04, momentum=0.9),
              metrics=['accuracy'])

class stopCallback(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get('accuracy')>0.85):
      print("\nAkurasi telah mencapai 92%!")
      self.model.stop_training = True
callbacks = stopCallback()

history = model.fit(
    train_generator,
    steps_per_epoch=25,
    epochs=40,
    callbacks=[callbacks],
    validation_data=validation_generator,
    validation_steps=5,
    verbose=1
)

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
from google.colab import files
from keras.preprocessing import image
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
# %matplotlib inline

uploaded = files.upload()

for fn in uploaded.keys():

  #predict images
  path = fn
  img = image.load_img(path, target_size=(150,150))
  imgplot = plt.imshow(img)
  x = image.img_to_array(img)
  x= np.expand_dims(x, axis=0)

  images = np.vstack([x])
  classes = model.predict(images, batch_size=10)
  result = np.argmax(classes)

    
  print(np.max(classes))

  print(fn)
  if result == 0:
    print('ambon')
  elif result ==1:
    print('barangan')
  elif result ==2:
    print('cavendish')
  elif result ==3:
    print('genderuwo')
  elif result ==4:
    print('javaicecream')
  elif result ==5:
    print('kepok')
  elif result ==6:
    print('mas')
  elif result ==7:
    print('nangka')
  elif result ==8:
    print('raja')
  elif result ==9:
    print('susu')
  elif result ==10:
    print('tanduk')
  elif result ==11:
    print('uli')
  else :
    print('not detected')

acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']
epochs = range(len(acc))

plt.plot(epochs, acc, 'r', label='Training accuracy')
plt.plot(epochs, val_acc, 'b', label='Validation accuracy')
plt.title('Training and validation accuracy')
plt.legend(loc=0)
plt.figure()

plt.plot(epochs, loss, 'r', label='Training loss')
plt.plot(epochs, val_loss, 'b', label='Validation loss')
plt.title('Training and validation loss')
plt.legend(loc=0)

plt.show()

converter = tf.lite.TFLiteConverter.from_keras_model(model)
tflite_model = converter.convert()

with tf.io.gfile.GFile('deteksi pisang 0.2.tflite', 'wb') as f:
  f.write(tflite_model)

history2 = model.fit(
    train_generator,
    steps_per_epoch=25,
    epochs=10,
    callbacks=[callbacks],
    validation_data=validation_generator,
    validation_steps=5,
    verbose=1
)

acc = history2.history['accuracy']
val_acc = history2.history['val_accuracy']
loss = history2.history['loss']
val_loss = history2.history['val_loss']
epochs = range(len(acc))

plt.plot(epochs, acc, 'r', label='Training accuracy')
plt.plot(epochs, val_acc, 'b', label='Validation accuracy')
plt.title('Training and validation accuracy')
plt.legend(loc=0)
plt.figure()

plt.plot(epochs, loss, 'r', label='Training loss')
plt.plot(epochs, val_loss, 'b', label='Validation loss')
plt.title('Training and validation loss')
plt.legend(loc=0)

plt.show()

